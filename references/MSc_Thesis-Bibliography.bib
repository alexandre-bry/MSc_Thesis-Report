@Article{Li2022,
  author    = {Li, Xiao and Qiu, Fang and Shi, Fan and Tang, Yunwei},
  journal   = {Remote Sensing},
  title     = {A Recursive Hull and Signal-Based Building Footprint Generation from Airborne LiDAR Data},
  year      = {2022},
  issn      = {2072-4292},
  month     = nov,
  number    = {22},
  pages     = {5892},
  volume    = {14},
  doi       = {10.3390/rs14225892},
  file      = {:Li2022 - A Recursive Hull and Signal Based Building Footprint Generation from Airborne LiDAR Data.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {MDPI AG},
}

@Article{Zhang2006,
  author    = {Zhang, K. and Yan, J. and Chen, S.-C.},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  title     = {Automatic Construction of Building Footprints From Airborne LIDAR Data},
  year      = {2006},
  issn      = {0196-2892},
  month     = sep,
  number    = {9},
  pages     = {2523--2533},
  volume    = {44},
  doi       = {10.1109/tgrs.2006.874137},
  file      = {:Zhang2006 - Automatic Construction of Building Footprints from Airborne LIDAR Data.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{Chajaei2025,
  author    = {Chajaei, Fatemeh and Bagheri, Hossein},
  journal   = {Remote Sensing Applications: Society and Environment},
  title     = {LOD1 3D city model from LiDAR: The impact of segmentation accuracy on quality of urban 3D modeling and morphology extraction},
  year      = {2025},
  issn      = {2352-9385},
  month     = apr,
  pages     = {101534},
  volume    = {38},
  doi       = {10.1016/j.rsase.2025.101534},
  file      = {:Chajaei2025 - LOD1 3D City Model from LiDAR_ the Impact of Segmentation Accuracy on Quality of Urban 3D Modeling and Morphology Extraction.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Elsevier BV},
}

@Article{Karsli2024,
  author    = {Karsli, Buray and Yilmazturk, Ferruh and Bahadir, Murat and Karsli, Fevzi and Ozdemir, Emirhan},
  journal   = {Journal of Building Engineering},
  title     = {Automatic building footprint extraction from photogrammetric and LiDAR point clouds using a novel improved-Octree approach},
  year      = {2024},
  issn      = {2352-7102},
  month     = apr,
  pages     = {108281},
  volume    = {82},
  doi       = {10.1016/j.jobe.2023.108281},
  file      = {:Karsli2024 - Automatic Building Footprint Extraction from Photogrammetric and LiDAR Point Clouds Using a Novel Improved Octree Approach.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Elsevier BV},
}

@Article{Jifroudi2022,
  author    = {Jifroudi, Hamidreza Maskani and Mansor, Shattri B. and Pradhan, Biswajeet and Halin, Alfian Abdul and Ahmad, Noordin and Abdullah, Ahmad Fikri Bin},
  journal   = {Measurement},
  title     = {A new approach to derive buildings footprint from light detection and ranging data using rule-based learning techniques and decision tree},
  year      = {2022},
  issn      = {0263-2241},
  month     = mar,
  pages     = {110781},
  volume    = {192},
  doi       = {10.1016/j.measurement.2022.110781},
  file      = {:Jifroudi2022 - A New Approach to Derive Buildings Footprint from Light Detection and Ranging Data Using Rule Based Learning Techniques and Decision Tree.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Elsevier BV},
}

@InProceedings{Haithcoat,
  author     = {Haithcoat, T.L. and Song, W. and Hipple, J.D.},
  booktitle  = {IEEE/ISPRS Joint Workshop on Remote Sensing and Data Fusion over Urban Areas (Cat. No.01EX482)},
  title      = {Building footprint extraction and 3-D reconstruction from LIDAR data},
  pages      = {74--78},
  publisher  = {IEEE},
  series     = {DFUA-01},
  collection = {DFUA-01},
  doi        = {10.1109/dfua.2001.985730},
  file       = {:Haithcoat - Building Footprint Extraction and 3 D Reconstruction from LIDAR Data.pdf:PDF},
  groups     = {Footprint and roofprint},
}

@Article{Sampath2007,
  author    = {Sampath, Aparajithan and Shan, Jie},
  journal   = {Photogrammetric Engineering &amp; Remote Sensing},
  title     = {Building Boundary Tracing and Regularization from Airborne Lidar Point Clouds},
  year      = {2007},
  issn      = {0099-1112},
  month     = jul,
  number    = {7},
  pages     = {805--812},
  volume    = {73},
  doi       = {10.14358/pers.73.7.805},
  file      = {:Sampath2007 - Building Boundary Tracing and Regularization from Airborne Lidar Point Clouds.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {American Society for Photogrammetry and Remote Sensing},
}

@Article{Li2025,
  author    = {Li, Zhixin},
  title     = {PRIMITIVE-BASED BUILDING MODEL RECONSTRUCTION FROM POINT CLOUDS},
  year      = {2025},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.25394/PGS.28832294.V1},
  file      = {:Li2025 - PRIMITIVE BASED BUILDING MODEL RECONSTRUCTION fROM POINT CLOUDS.pdf:PDF},
  groups    = {Footprint and roofprint},
  keywords  = {Civil engineering not elsewhere classified},
  publisher = {Purdue University Graduate School},
}

@Article{Awrangjeb2016,
  author    = {Awrangjeb, M.},
  journal   = {International Journal of Remote Sensing},
  title     = {Using point cloud data to identify, trace, and regularize the outlines of buildings},
  year      = {2016},
  issn      = {1366-5901},
  month     = jan,
  number    = {3},
  pages     = {551--579},
  volume    = {37},
  doi       = {10.1080/01431161.2015.1131868},
  file      = {:Awrangjeb2016 - Using Point Cloud Data to Identify, Trace, and Regularize the Outlines of Buildings.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Informa UK Limited},
}

@Article{Widyaningrum2019,
  author    = {Widyaningrum, Elyta and Gorte, Ben and Lindenbergh, Roderik},
  journal   = {Remote Sensing},
  title     = {Automatic Building Outline Extraction from ALS Point Clouds by Ordered Points Aided Hough Transform},
  year      = {2019},
  issn      = {2072-4292},
  month     = jul,
  number    = {14},
  pages     = {1727},
  volume    = {11},
  doi       = {10.3390/rs11141727},
  file      = {:Widyaningrum2019 - Automatic Building Outline Extraction from ALS Point Clouds by Ordered Points Aided Hough Transform.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {MDPI AG},
}

@Article{Widyaningrum2020,
  author            = {Widyaningrum, Elyta and Peters, Ravi Y. and Lindenbergh, Roderik C.},
  journal           = {Pattern Recognition},
  title             = {Building outline extraction from ALS point clouds using medial axis transform descriptors},
  year              = {2020},
  issn              = {0031-3203},
  month             = oct,
  pages             = {107447},
  volume            = {106},
  comment-alexandre = {They talk about overhanging roofs here as a source of errors compared to the BAG.},
  doi               = {10.1016/j.patcog.2020.107447},
  file              = {:Widyaningrum2020 - Building Outline Extraction from ALS Point Clouds Using Medial Axis Transform Descriptors.pdf:PDF},
  groups            = {Footprint and roofprint},
  publisher         = {Elsevier BV},
}

@Article{Dorninger2008,
  author    = {Dorninger, Peter and Pfeifer, Norbert},
  journal   = {Sensors},
  title     = {A Comprehensive Automated 3D Approach for Building Extraction, Reconstruction, and Regularization from Airborne Laser Scanning Point Clouds},
  year      = {2008},
  issn      = {1424-8220},
  month     = nov,
  number    = {11},
  pages     = {7323--7343},
  volume    = {8},
  doi       = {10.3390/s8117323},
  file      = {:Dorninger2008 - A Comprehensive Automated 3D Approach for Building Extraction, Reconstruction, and Regularization from Airborne Laser Scanning Point Clouds.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {MDPI AG},
}

@Article{Kong2022,
  author    = {Kong, Gefei and Fan, Hongchao and Lobaccaro, Gabriele},
  journal   = {Geocarto International},
  title     = {Automatic building outline extraction from ALS point cloud data using generative adversarial network},
  year      = {2022},
  issn      = {1752-0762},
  month     = aug,
  number    = {27},
  pages     = {15964--15981},
  volume    = {37},
  doi       = {10.1080/10106049.2022.2102246},
  file      = {:Kong2022 - Automatic Building Outline Extraction from ALS Point Cloud Data Using Generative Adversarial Network.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Informa UK Limited},
}

@Article{Albers2016,
  author    = {Albers, Bastian and Kada, Martin and Wichmann, Andreas},
  journal   = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  title     = {AUTOMATIC EXTRACTION AND REGULARIZATION OF BUILDING OUTLINES FROM AIRBORNE LIDAR POINT CLOUDS},
  year      = {2016},
  issn      = {2194-9034},
  month     = jun,
  pages     = {555--560},
  volume    = {XLI-B3},
  doi       = {10.5194/isprs-archives-xli-b3-555-2016},
  file      = {:Albers2016 - AUTOMATIC EXTRACTION aND REGULARIZATION oF BUILDING OUTLINES fROM AIRBORNE LIDAR POINT CLOUDS.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Copernicus GmbH},
}

@Article{Frommholz2017,
  author            = {Frommholz, D. and Linkiewicz, M. and Meissner, H. and Dahlke, D.},
  journal           = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  title             = {RECONSTRUCTING BUILDINGS WITH DISCONTINUITIES AND ROOF OVERHANGS FROM OBLIQUE AERIAL IMAGERY},
  year              = {2017},
  issn              = {2194-9034},
  month             = may,
  pages             = {465--471},
  volume            = {XLII-1/W1},
  comment-alexandre = {Very technical and not many images. The part about roof overhangs is very small but simple and potentially efficient by requiring a DSM and the footprint.

The process is:
- Make a dense point cloud from aerial oblique images
- Reconstruct the building without overhangs with a somewhat complex process involving defining neighbourhoods, guessing edges and planes and intersecting planes to get the polygons, in 2D or 3D when 2D doesn't work
- Adding the overhangs by projecting the footprint (based on the walls) onto the DSM of the scene
- Then texture mapping},
  doi               = {10.5194/isprs-archives-xlii-1-w1-465-2017},
  file              = {:Frommholz2017 - RECONSTRUCTING BUILDINGS wITH DISCONTINUITIES aND ROOF OVERHANGS fROM OBLIQUE AERIAL IMAGERY.pdf:PDF},
  groups            = {Footprint and roofprint},
  publisher         = {Copernicus GmbH},
  readstatus        = {read},
  relevance         = {relevant},
}

@InProceedings{Goebbels2023,
  author            = {Goebbels, Steffen and Pohle-Fröhlich, Regina},
  booktitle         = {Proceedings of the 18th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  title             = {Automatic Reconstruction of Roof Overhangs for 3D City Models},
  year              = {2023},
  pages             = {145--152},
  publisher         = {SCITEPRESS - Science and Technology Publications},
  comment-alexandre = {Probably not very relevant because requires a LoD model as an input as well as the point cloud, and the decisions taken seem relatively basic. But still interersting to see.

Open-source code https://github.com/ SteffenGoebbels/citygml_overhangs
Switzerland 3D models with roof overhangs by hand https://www.swisstopo.admin.ch/de/geodata/ landscape/buildings3d2.html
Steps:
- Detect potential overhang edges (on the edge of the roof + parallel and close horizontally to footprint edges + other things)
- Compute potential overhang
- Size is derived either from an image or from a point cloud. For the point cloud, they extract all the points in a horizontal area of 2 meters around an edge, and try to determine which points are part of the plane with simple thresholds},
  doi               = {10.5220/0011604200003417},
  file              = {:Goebbels2023 - Automatic Reconstruction of Roof Overhangs for 3D City Models.pdf:PDF},
  groups            = {Footprint and roofprint},
  readstatus        = {read},
}

@Article{Wysocki2022,
  author    = {Wysocki, Olaf and Hoegner, Ludwig and Stilla, Uwe},
  journal   = {International Journal of Applied Earth Observation and Geoinformation},
  title     = {Refinement of semantic 3D building models by reconstructing underpasses from MLS point clouds},
  year      = {2022},
  issn      = {1569-8432},
  month     = jul,
  pages     = {102841},
  volume    = {111},
  doi       = {10.1016/j.jag.2022.102841},
  file      = {:Wysocki2022 - Refinement of Semantic 3D Building Models by Reconstructing Underpasses from MLS Point Clouds.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Elsevier BV},
}

@Article{Wang2016,
  author    = {Wang, Yongjun and Xu, Hao and Cheng, Liang and Li, Manchun and Wang, Yajun and Xia, Nan and Chen, Yanming and Tang, Yong},
  journal   = {Remote Sensing},
  title     = {Three-Dimensional Reconstruction of Building Roofs from Airborne LiDAR Data Based on a Layer Connection and Smoothness Strategy},
  year      = {2016},
  issn      = {2072-4292},
  month     = may,
  number    = {5},
  pages     = {415},
  volume    = {8},
  doi       = {10.3390/rs8050415},
  file      = {:Wang2016 - Three Dimensional Reconstruction of Building Roofs from Airborne LiDAR Data Based on a Layer Connection and Smoothness Strategy.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {MDPI AG},
}

@Article{Panday2012,
  author            = {Panday, U. S. and Gerke, M.},
  journal           = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  title             = {FITTING OF PARAMETRIC BUILDING MODELS TO OBLIQUE AERIAL IMAGES},
  year              = {2012},
  issn              = {2194-9034},
  month             = sep,
  pages             = {233--238},
  volume            = {XXXVIII-4/W19},
  comment-alexandre = {Relire pour en savoir plus

This paper has nice illustrations and is interesting.

The method for overhang estimation seems to be:
- Determine the edges of the roof
- Find the corresponding wall by finding the best fit for a vertical plane aligned with each edge by sweeping the plane perpendicularly to the edge. Symmetry is also used to assume that the overhang will be the same on the other side and therefore have more samples to get a better result.},
  doi               = {10.5194/isprsarchives-xxxviii-4-w19-233-2011},
  file              = {:Panday2012 - FITTING oF PARAMETRIC BUILDING MODELS tO OBLIQUE AERIAL IMAGES.pdf:PDF},
  groups            = {Footprint and roofprint},
  publisher         = {Copernicus GmbH},
  readstatus        = {read},
}

@Article{JarzabekRychard2017,
  author            = {Jarząbek-Rychard, Małgorzata and Maas, Hans-Gerd},
  journal           = {Remote Sensing},
  title             = {Geometric Refinement of ALS-Data Derived Building Models Using Monoscopic Aerial Images},
  year              = {2017},
  issn              = {2072-4292},
  month             = mar,
  number            = {3},
  pages             = {282},
  volume            = {9},
  comment-alexandre = {Look at citations

Nice article dealing with enhancing the precision of roofprint extraction from ALS, especially errors due to occlusion, by enhancing it with a single aerial image.

A method to improve the quality of 3D buildings made from ALS point clouds using a single aerial image:
- Start from an ALS-based roofprint
- Detect edges from image with the Canny edge detector and a modified region growing algorithm
- Link lines detected from the image to the ALS edges
- Refine the roof planes with the edges from the image},
  doi               = {10.3390/rs9030282},
  file              = {:JarzabekRychard2017 - Geometric Refinement of ALS Data Derived Building Models Using Monoscopic Aerial Images.pdf:PDF},
  groups            = {Footprint and roofprint},
  publisher         = {MDPI AG},
  readstatus        = {read},
}

@InProceedings{Zhang2020,
  author    = {Zhang, Su and Han, Fei and Bogus, Susan M.},
  booktitle = {Construction Research Congress 2020},
  title     = {Building Footprint and Height Information Extraction from Airborne LiDAR and Aerial Imagery},
  year      = {2020},
  month     = nov,
  pages     = {326--335},
  publisher = {American Society of Civil Engineers},
  doi       = {10.1061/9780784482865.035},
  groups    = {Footprint and roofprint},
}

@InProceedings{Wang2006,
  author    = {Wang, Oliver and Lodha, Suresh K. and Helmbold, David P.},
  booktitle = {Third International Symposium on 3D Data Processing, Visualization, and Transmission (3DPVT’06)},
  title     = {A Bayesian Approach to Building Footprint Extraction from Aerial LIDAR Data},
  year      = {2006},
  month     = jun,
  pages     = {192--199},
  publisher = {IEEE},
  doi       = {10.1109/3dpvt.2006.9},
  groups    = {Footprint and roofprint},
}

@InProceedings{hackel2017isprs,
  author    = {Timo Hackel and N. Savinov and L. Ladicky and Jan D. Wegner and K. Schindler and M. Pollefeys},
  booktitle = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  title     = {{SEMANTIC3D.NET: A new large-scale point cloud classification benchmark}},
  year      = {2017},
  pages     = {91--98},
  volume    = {IV-1-W1},
  file      = {:hackel2017isprs - SEMANTIC3D.NET_ a New Large Scale Point Cloud Classification Benchmark.pdf:PDF},
  groups    = {Point cloud classification},
  url       = {https://semantic3d.ethz.ch/index-2.html},
}

@Article{Liu2025,
  author    = {Liu, Ke and Ma, Hongchao and Li, Li and Huang, Shixin and Zhang, Liang and Liang, Xiaoli and Cai, Zhan},
  journal   = {Remote Sensing},
  title     = {Building Outline Extraction via Topology-Aware Loop Parsing and Parallel Constraint from Airborne LiDAR},
  year      = {2025},
  issn      = {2072-4292},
  month     = oct,
  number    = {20},
  pages     = {3498},
  volume    = {17},
  doi       = {10.3390/rs17203498},
  file      = {:Liu2025 - Building Outline Extraction Via Topology Aware Loop Parsing and Parallel Constraint from Airborne LiDAR.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {MDPI AG},
}

@Article{Kong2023,
  author    = {Kong, Gefei and Fan, Hongchao},
  journal   = {Geo-spatial Information Science},
  title     = {PH-shape: an adaptive persistent homology-based approach for building outline extraction from ALS point cloud data},
  year      = {2023},
  issn      = {1993-5153},
  month     = dec,
  number    = {4},
  pages     = {1107--1117},
  volume    = {27},
  doi       = {10.1080/10095020.2023.2280569},
  file      = {:Kong2023 - PH Shape_ an Adaptive Persistent Homology Based Approach for Building Outline Extraction from ALS Point Cloud Data.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {Informa UK Limited},
}

@Article{Hu2021,
  author    = {Hu, Pingbo and Miao, Yiming and Hou, Miaole},
  journal   = {Remote Sensing},
  title     = {Reconstruction of Complex Roof Semantic Structures from 3D Point Clouds Using Local Convexity and Consistency},
  year      = {2021},
  issn      = {2072-4292},
  month     = may,
  number    = {10},
  pages     = {1946},
  volume    = {13},
  doi       = {10.3390/rs13101946},
  file      = {:Hu2021 - Reconstruction of Complex Roof Semantic Structures from 3D Point Clouds Using Local Convexity and Consistency.pdf:PDF},
  groups    = {Footprint and roofprint},
  publisher = {MDPI AG},
}

@Misc{Wu2023,
  author            = {Wu, Xiaoyang and Jiang, Li and Wang, Peng-Shuai and Liu, Zhijian and Liu, Xihui and Qiao, Yu and Ouyang, Wanli and He, Tong and Zhao, Hengshuang},
  title             = {Point Transformer V3: Simpler, Faster, Stronger},
  year              = {2023},
  comment-alexandre = {Very interesting paper, with associated code
Focuses on simplicity to allow for efficiency and therefore scalability of the model. Moreover, uses point cloud serialisation to add structure to the point cloud and remove the need for costly neighbours computations.
This results in a smaller and faster model that achieves state-of-the-art results.},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.2312.10035},
  file              = {:Wu2023 - Point Transformer V3_ Simpler, Faster, Stronger.pdf:PDF},
  groups            = {Point cloud classification},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher         = {arXiv},
  readstatus        = {read},
}

@Article{Dahlke2015,
  author            = {Dahlke, Dennis and Linkiewicz, Magdalena and Meissner, Henry},
  journal           = {International Journal of Image and Data Fusion},
  title             = {True 3D building reconstruction: façade, roof and overhang modelling from oblique and vertical aerial imagery},
  year              = {2015},
  issn              = {1947-9824},
  month             = aug,
  number            = {4},
  pages             = {314--329},
  volume            = {6},
  comment-alexandre = {This paper is nice, but maybe a bit old?

This paper deals with building reconstruction from a 3D point cloud made from oblique images. The methode is divided in 3 steps:
1. Extract the footprint from façades after removing roof and ground points
2. Segment and reconstruct the roof in 3D using planarity, region growing and edges with the façades
3. Add roof overhangs using a DSM and the computed footprint. They look at the median height (in the DSM) along a line that is parallel to the façade at different distances (step of one DSM pixel), outside the building. They look up to 1.5 m away and the overall gradient should be at least 2 m. In the list of median heights, they use the highest gradient as a first approximation, and then fit a cubic polynomial function around that value to get a sub-pixel approximation.},
  doi               = {10.1080/19479832.2015.1071287},
  file              = {:19479832.2015.1071287.pdf:PDF},
  groups            = {Footprint and roofprint},
  publisher         = {Informa UK Limited},
  readstatus        = {read},
}

@Article{Koelle2021,
  author            = {Kölle, Michael and Laupheimer, Dominik and Schmohl, Stefan and Haala, Norbert and Rottensteiner, Franz and Wegner, Jan Dirk and Ledoux, Hugo},
  journal           = {ISPRS Open Journal of Photogrammetry and Remote Sensing},
  title             = {The Hessigheim 3D (H3D) benchmark on semantic segmentation of high-resolution 3D point clouds and textured meshes from UAV LiDAR and Multi-View-Stereo},
  year              = {2021},
  issn              = {2667-3932},
  month             = oct,
  pages             = {100001},
  volume            = {1},
  comment-alexandre = {Benchmark on semantic segmentation of high-resolution 3D point clouds and textured meshes. Classes include roofs and façades.},
  doi               = {10.1016/j.ophoto.2021.100001},
  file              = {:Koelle2021 - The Hessigheim 3D (H3D) Benchmark on Semantic Segmentation of High Resolution 3D Point Clouds and Textured Meshes from UAV LiDAR and Multi View Stereo.pdf:PDF},
  groups            = {Benchmark or data, Point cloud classification},
  publisher         = {Elsevier BV},
}

@Article{Niemeyer2014,
  author            = {Niemeyer, Joachim and Rottensteiner, Franz and Soergel, Uwe},
  journal           = {ISPRS Journal of Photogrammetry and Remote Sensing},
  title             = {Contextual classification of lidar data and building object detection in urban areas},
  year              = {2014},
  issn              = {0924-2716},
  month             = jan,
  pages             = {152--165},
  volume            = {87},
  comment-alexandre = {Benchmark for 3D Semantic Labeling. Classes include roofs and façades.
Link: https://www.isprs.org/resources/datasets/benchmarks/UrbanSemLab/Default.aspx},
  doi               = {10.1016/j.isprsjprs.2013.11.001},
  file              = {:Niemeyer2014 - Contextual Classification of Lidar Data and Building Object Detection in Urban Areas.pdf:PDF},
  groups            = {Benchmark or data, Point cloud classification},
  publisher         = {Elsevier BV},
}

@Article{Zachar2023,
  author            = {Zachar, P. and Bakuła, K. and Ostrowski, W.},
  journal           = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  title             = {CENAGIS-ALS BENCHMARK - NEW PROPOSAL FOR DENSE ALS BENCHMARK BASED ON THE REVIEW OF DATASETS AND BENCHMARKS FOR 3D POINT CLOUD SEGMENTATION},
  year              = {2023},
  issn              = {2194-9034},
  month             = oct,
  pages             = {227--234},
  volume            = {XLVIII-1/W3-2023},
  comment-alexandre = {A recent benchmark for 3D point cloud classification with lots of classes and high density point cloud.
It also lists many existing benchmarks.},
  doi               = {10.5194/isprs-archives-xlviii-1-w3-2023-227-2023},
  file              = {:Zachar2023 - CENAGIS ALS BENCHMARK NEW PROPOSAL fOR DENSE ALS BENCHMARK BASED oN tHE REVIEW oF DATASETS aND BENCHMARKS fOR 3D POINT CLOUD SEGMENTATION.pdf:PDF},
  groups            = {Benchmark or data, Point cloud classification},
  publisher         = {Copernicus GmbH},
}

@Misc{Biasutti2019,
  author            = {Biasutti, Pierre and Bugeau, Aurélie and Aujol, Jean-François and Brédif, Mathieu},
  title             = {RIU-Net: Embarrassingly simple semantic segmentation of 3D LiDAR point cloud},
  year              = {2019},
  comment-alexandre = {Seems to aim for simplicity and speed. Trained on TLS.
Uses the concept of range-images, which requires to know the source of the image.
Puts a simple U-Net on top of it, performing remarkably well on TLS data compared to state-of-the-art.},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.1905.08748},
  file              = {:Biasutti2019 - RIU Net_ Embarrassingly Simple Semantic Segmentation of 3D LiDAR Point Cloud.pdf:PDF},
  groups            = {Point cloud classification},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher         = {arXiv},
  readstatus        = {read},
}

@Misc{Thomas2019,
  author            = {Thomas, Hugues and Qi, Charles R. and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, François and Guibas, Leonidas J.},
  title             = {KPConv: Flexible and Deformable Convolution for Point Clouds},
  year              = {2019},
  comment-alexandre = {Very interesting paper that extends convolutional layers to point clouds with great flexibility and impressive results.},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.1904.08889},
  file              = {:Thomas2019 - KPConv_ Flexible and Deformable Convolution for Point Clouds.pdf:PDF},
  groups            = {Point cloud classification},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher         = {arXiv},
  readstatus        = {read},
}

@InProceedings{Choy2019,
  author            = {Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},
  booktitle         = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title             = {4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks},
  year              = {2019},
  month             = jun,
  pages             = {3070--3079},
  publisher         = {IEEE},
  comment-alexandre = {Crucial paper introducing generalised sparse convolutions combining 3D data and time to process what they call 3D-videos (which includes LiDAR scans).
It is very technical and comes with code: https://github.com/StanfordVL/MinkowskiEngine
This introduced mostly a new type of layer with a goal similar to dense convolutional layers, and is used in the paper with structures similar to ResNet and UNet, but there has probably been many models made with these layers in the last few years.},
  doi               = {10.1109/cvpr.2019.00319},
  file              = {:Choy2019 - 4D Spatio Temporal ConvNets_ Minkowski Convolutional Neural Networks.pdf:PDF},
  groups            = {Point cloud classification},
  readstatus        = {read},
}

@Article{Li2020,
  author            = {Li, Wuzhao and Wang, Fu-Dong and Xia, Gui-Song},
  journal           = {ISPRS Journal of Photogrammetry and Remote Sensing},
  title             = {A geometry-attentional network for ALS point cloud classification},
  year              = {2020},
  issn              = {0924-2716},
  month             = jun,
  pages             = {26--40},
  volume            = {164},
  comment-alexandre = {Interesting paper that uses its own version of 3D convolution for point clouds, and combines a dense hierarchical network (a kind of dense UNet) with a so-called elevation-attention module that is attention computed with a MLP from the height values.
They tested their model specifically on ALS data with nice results, and with the distinction between roof and façades, even though façades don't have the best score.
They use (x, y, z, intensity, return_number) as input for each point.},
  doi               = {10.1016/j.isprsjprs.2020.03.016},
  file              = {:Li2020 - A Geometry Attentional Network for ALS Point Cloud Classification.pdf:PDF},
  groups            = {Point cloud classification},
  publisher         = {Elsevier BV},
  readstatus        = {read},
}

@Misc{Zhao2020,
  author            = {Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip and Koltun, Vladlen},
  title             = {Point Transformer},
  year              = {2020},
  comment-alexandre = {Very nice paper introducing a self-attention layer applicable to 3D point clouds. With farthest point sampling and trilinear interpolation it allows to build a U-net architecture that outperformed other models at that time in semantic segmentation.
Unofficial implementation (couldn't find an official one): https://github.com/POSTECH-CVLab/point-transformer},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.2012.09164},
  file              = {:Zhao2020 - Point Transformer.pdf:PDF},
  groups            = {Point cloud classification},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher         = {arXiv},
  readstatus        = {read},
}

@Misc{Deng2022,
  author    = {Deng, Xin and Zhang, WenYu and Ding, Qing and Zhang, XinMing},
  title     = {PointVector: A Vector Representation In Point Cloud Analysis},
  year      = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2205.10528},
  file      = {:Deng2022 - PointVector_ a Vector Representation in Point Cloud Analysis.pdf:PDF},
  groups    = {Point cloud classification},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{Guo2019,
  author            = {Guo, Yulan and Wang, Hanyun and Hu, Qingyong and Liu, Hao and Liu, Li and Bennamoun, Mohammed},
  title             = {Deep Learning for 3D Point Clouds: A Survey},
  year              = {2019},
  comment-alexandre = {https://github.com/QingyongHu/SoTA-Point-Cloud},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.1912.12033},
  file              = {:Guo2019 - Deep Learning for 3D Point Clouds_ a Survey.pdf:PDF},
  groups            = {Point cloud classification, Benchmark or data},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Robotics (cs.RO), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  publisher         = {arXiv},
}

@Misc{Varney2020,
  author            = {Varney, Nina and Asari, Vijayan K. and Graehling, Quinn},
  title             = {DALES: A Large-scale Aerial LiDAR Data Set for Semantic Segmentation},
  year              = {2020},
  comment-alexandre = {Links to get the data don't seem to work anymore},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.2004.11985},
  file              = {:Varney2020 - DALES_ a Large Scale Aerial LiDAR Data Set for Semantic Segmentation.pdf:PDF},
  groups            = {Benchmark or data},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher         = {arXiv},
}

@Misc{Hu2020,
  author            = {Hu, Qingyong and Yang, Bo and Khalid, Sheikh and Xiao, Wen and Trigoni, Niki and Markham, Andrew},
  title             = {Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset, Benchmarks and Challenges},
  year              = {2020},
  comment-alexandre = {https://github.com/QingyongHu/SensatUrban},
  copyright         = {arXiv.org perpetual, non-exclusive license},
  doi               = {10.48550/ARXIV.2009.03137},
  file              = {:Hu2020 - Towards Semantic Segmentation of Urban Scale 3D Point Clouds_ a Dataset, Benchmarks and Challenges.pdf:PDF},
  groups            = {Benchmark or data},
  keywords          = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher         = {arXiv},
}

@Article{Zhang2016,
  author    = {Zhang, Zhenxin and Zhang, Liqiang and Tong, Xiaohua and Mathiopoulos, P. Takis and Guo, Bo and Huang, Xianfeng and Wang, Zhen and Wang, Yuebin},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  title     = {A Multilevel Point-Cluster-Based Discriminative Feature for ALS Point Cloud Classification},
  year      = {2016},
  issn      = {1558-0644},
  month     = jun,
  number    = {6},
  pages     = {3309--3321},
  volume    = {54},
  doi       = {10.1109/tgrs.2016.2514508},
  file      = {:Zhang2016 - A Multilevel Point Cluster Based Discriminative Feature for ALS Point Cloud Classification.pdf:PDF},
  groups    = {Point cloud classification},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{Dai2025,
  author     = {Dai, Hengming and Xu, Jiabo and Hu, Xiangyun and Shu, Zhen and Ma, Wei and Zhao, Zhifang},
  journal    = {International Journal of Applied Earth Observation and Geoinformation},
  title      = {Deep projective prediction of building facade footprints from ALS point cloud},
  year       = {2025},
  issn       = {1569-8432},
  month      = may,
  pages      = {104448},
  volume     = {139},
  doi        = {10.1016/j.jag.2025.104448},
  file       = {:Dai2025 - Deep Projective Prediction of Building Facade Footprints from ALS Point Cloud.pdf:PDF},
  groups     = {Footprint and roofprint},
  publisher  = {Elsevier BV},
  readstatus = {skimmed},
}

@Article{Li2024,
  author            = {Li, Mengtian and Lin, Shaohui and Wang, Zihan and Shen, Yunhang and Zhang, Baochang and Ma, Lizhuang},
  journal           = {Pattern Recognition},
  title             = {Class-imbalanced semi-supervised learning for large-scale point cloud semantic segmentation via decoupling optimization},
  year              = {2024},
  issn              = {0031-3203},
  month             = dec,
  pages             = {110701},
  volume            = {156},
  comment-alexandre = {Great paper that combines imbalanced datasets and semi-supervised learning.
I haven't understood the technical details entirely, but the main idea is to decouple the optimization of the backbone (feature extraction) and the classifier, by alternating them. Optimization of the backbone happens on a rebalanced set of points, using ground-truth points and pseudo-labelled points, as well as a custom "Multi-Class Imbalanced Focus Loss.". Optimization of the classifier uses only ground-truth labels and a standard softmax cross-entropy loss.},
  doi               = {10.1016/j.patcog.2024.110701},
  file              = {:Li2024 - Class Imbalanced Semi Supervised Learning for Large Scale Point Cloud Semantic Segmentation Via Decoupling Optimization.pdf:PDF},
  groups            = {Point cloud classification},
  publisher         = {Elsevier BV},
  readstatus        = {read},
}

@Article{Zou2023,
  author            = {{Zou, Yunfan}},
  title             = {Analysis of the Long Tail Problem in Semantic Segmentation with 3D Point Clouds},
  year              = {2023},
  comment-alexandre = {A MSc thesis about the long tail problem in semantic segmentation which provides a nice overview of the methods that exist, but does not really achieve significant results.
Code there: https://github.com/ivanzou29/SpatioTemporalSegmentation-ScanNet},
  doi               = {10.3929/ETHZ-B-000606777},
  file              = {:Zou2023 - Analysis of the Long Tail Problem in Semantic Segmentation with 3D Point Clouds.pdf:PDF},
  groups            = {Point cloud classification},
  language          = {en},
  publisher         = {ETH Zurich},
  readstatus        = {skimmed},
}

@Article{Pan2025,
  author            = {Pan, Zhiyi and Zhang, Nan and Gao, Wei and Liu, Shan and Li, Ge},
  journal           = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title             = {Point Cloud Semantic Segmentation with Sparse and Inhomogeneous Annotations},
  year              = {2025},
  issn              = {2159-5399},
  month             = apr,
  number            = {6},
  pages             = {6354--6362},
  volume            = {39},
  comment-alexandre = {Code at: https://github.com/panzhiyi/AADNet
Proposes a framework to train point cloud semantic segmentation models with weakly supervised training by taking into account the inhomogeneity of labelling. To do so, they propose different strategies:
- Downsampling in two different ways:
	- Point level downsampling to prioritise labelled points
	- Voxel-level downsampling to prioritise topology and structure
- A gradient calibration function to compensate the bias introduced by annotation inhomogeneity
I haven't understood the technical details entirely though, and especially I'm wondering if, why and how subsampling would be used in training point clouds with less sparse annotations.},
  doi               = {10.1609/aaai.v39i6.32680},
  file              = {:Pan2025 - Point Cloud Semantic Segmentation with Sparse and Inhomogeneous Annotations.pdf:PDF},
  groups            = {Point cloud classification},
  publisher         = {Association for the Advancement of Artificial Intelligence (AAAI)},
  readstatus        = {read},
}

@Article{Merizette2025,
  author     = {Mérizette, Maxime and Audebert, Nicolas and Kervella, Pierre and Verdun, Jérôme},
  title      = {3DSES: an indoor Lidar point cloud segmentation dataset with real and pseudo-labels from a 3D model},
  year       = {2025},
  copyright  = {arXiv.org perpetual, non-exclusive license},
  doi        = {10.48550/ARXIV.2501.17534},
  file       = {:Merizette2025 - 3DSES_ an Indoor Lidar Point Cloud Segmentation Dataset with Real and Pseudo Labels from a 3D Model.pdf:PDF},
  groups     = {Benchmark or data, Read recently},
  keywords   = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher  = {arXiv},
  readstatus = {read},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Footprint and roofprint\;0\;1\;0x008000ff\;\;\;;
1 StaticGroup:Point cloud classification\;0\;0\;0xff0000ff\;\;\;;
1 StaticGroup:Read recently\;0\;1\;0x00ffffff\;CHAT_BUBBLE_OUTLINE\;\;;
1 StaticGroup:Benchmark or data\;0\;0\;0xff00ffff\;\;\;;
}
